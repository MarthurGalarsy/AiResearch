# 検討中の案
## 前提知識
* LangChainのAgent機能はToolを持たせる
* Toolにはname、func、descriptionが必要
* Toolは独自に作成、複数持たせることも可能
* descriptionに記載することが非常に重要、どのToolを使うかはここ次第
* LangChainのAgentにはzero-shot-react-descriptionというものがあり、Toolの中からどのツールを用いるか決めるらしい
* Agent自体がToolを選んで繰り返し実行してくれる機能を持っている、らしい

## 案１（楽観的に作成する考え）
* lama_hub.github_repoで取得、Vector化したデータをLangChainのToolに入れる
* agentを作成してプロンプトを流す（llmはgpt-4）

## 案２（全て１から作成する考え）
### 単ファイルに関するTool
* llama_hub.github_repoで取得したデータはファイル名とファイル内容を持っている
* Toolのnameにファイル名、descripntionにファイル名を組み込んでおく
* funcには１ファイルをVector化したデータを入れる
* これを全ファイルに対して行う
### 複数ファイルに関するTool
#### ファイル一覧（クラス一覧）
* ファイル名を全てソートしてListみたいにしておく
  * ローカルディレクトリからの場合、ファイル名を持っていないのでpackageとclass名から抜き出すことになる
* Toolのnameに全ファイルリスト、desciprionにも全ファイル一覧、All File Listなど引っかかるように作成
* funcにはファイル名を全てソートしたListをVector化したデータとして入れる
#### クラス図
* 各ファイルからpackage名、class名、メソッド名、import情報などを抽出する
* 抽出した情報をファイルごとにリスト化する
* Toolのnameにクラス図、desciprionにクラス図など引っかかるように作成
* funcに抽出した情報をVector化したデータとして入れる

というように作成するものごとに必要な情報を抜き出してまとめてVector化、Toolとして作成

最終的に全てのToolをagentに入れる

agentに入れるllmは現時点ではgpt-4が有力

# 今後の予定
* まずは案１のSampleを作成して精度を確認してみることとする（これまでのSampleとしては試していない）
* 案１はおそらく精度が高くないと予想されるので案２の単ファイル、クラス一覧などあたりを作成して確認してみる

# 参考
## Agentについて
* https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_agents
* https://book.st-hakky.com/docs/agents-of-langchain/
* https://note.com/hamachi_jp/n/n73ce891714d1
## LangChain Agent + LlamaIndex
* https://qiita.com/kzkymn/items/8739762fab8cf9d6edad
* https://dev.classmethod.jp/articles/lang-chain-agent-customized-by-llama-index-tool/
